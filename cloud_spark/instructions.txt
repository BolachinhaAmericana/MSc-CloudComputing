#New isntructions, paster on AI to get new dockerfile:

docker run -it --user 0 -v ~/spark_container:/opt/spark/work-dir apache/spark-py /bin/bash

# Dentro do terminal da imagem
apt-get update && apt-get upgrade
apt-get update && apt-get install -y libgl1 
apt-get update && apt-get install -y libglib2.0-0 

pip install --no-cache-dir -r requirements.txt

mkdir -p /opt/spark/jars
curl -o /opt/spark/jars/gcs-connector-hadoop3-latest.jar https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar

#run pytho file with pyspark
#spark-submit --jars /opt/spark/jars/gcs-connector-hadoop3-latest.jar <python file> -> We dont need to run this anymore, it runs inside the python script as subprocess

python3 main.py 
