{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Service (development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchxrayvision as xrv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.optim as optim \n",
    "import os\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "Torchvision version: 1.2.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {xrv.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset for finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def annotation_creation(image_path):\n",
    "    annotations_list_normal = []\n",
    "    annotations_list_pneumonia = []\n",
    "    for filename in os.listdir(image_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith('.jpeg'):\n",
    "            image_new_path = os.path.join(image_path,filename)\n",
    "            try:\n",
    "                img = Image.open(image_new_path)\n",
    "                img.verify() #  verify that it is, in fact an image\n",
    "                \n",
    "                if \"NORMAL\" in image_path.upper():\n",
    "                    annotations_list_normal.append({'filename': filename, 'label': 0})\n",
    "                elif \"PNEUMONIA\" in image_path.upper():\n",
    "                    annotations_list_pneumonia.append({\"filename\" : filename, \"label\" : 1})\n",
    "            except Exception as e:\n",
    "                print(f'Error loading imagage {filename}')\n",
    "                \n",
    "                \n",
    "    return annotations_list_normal, annotations_list_pneumonia\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train = r\"C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\train\\NORMAL\"\n",
    "pneumonia_train = r\"C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\train\\PNEUMONIA\"\n",
    "\n",
    "annotations_train_normal,_ = annotation_creation(normal_train)\n",
    "_,annotations_train_pneumonia = annotation_creation(pneumonia_train)\n",
    "\n",
    "print(f'Nº normal images for training {len(annotations_train_normal)}')\n",
    "print(f'Nº pneumonia images for training {len(annotations_train_pneumonia)}')\n",
    "print(f'Total images for training {len(annotations_train_normal) + len(annotations_train_pneumonia)}')\n",
    "print(f' Proportion of normal images for traing {len(annotations_train_normal)*100/ (len(annotations_train_normal) + len(annotations_train_pneumonia))}%')\n",
    "\n",
    "annotaded_train_images = annotations_train_normal + annotations_train_pneumonia\n",
    "\n",
    "print( annotaded_train_images)\n",
    "print(len(annotaded_train_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_val = r'C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\val\\NORMAL'\n",
    "pneumonia_val = r'C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\val\\PNEUMONIA'\n",
    "\n",
    "annotations_val_normal,_ = annotation_creation(normal_val)\n",
    "_,annotations_val_pneumonia = annotation_creation(pneumonia_val)\n",
    "\n",
    "\n",
    "print(f'Nº normal images for validation {len(annotations_val_normal)}')\n",
    "print(f'Nº pneumonia images for validation {len(annotations_val_pneumonia)}')\n",
    "print(f'Total images for validation {len(annotations_val_normal) + len(annotations_val_pneumonia)}')\n",
    "print(f' Proportion of normal images for validation {len(annotations_val_normal)*100/ (len(annotations_val_normal) + len(annotations_val_pneumonia))}%')\n",
    "\n",
    "annotaded_val_images = annotations_val_normal + annotations_val_pneumonia\n",
    "\n",
    "print( annotaded_val_images)\n",
    "print(len(annotaded_val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test = r'C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\test\\NORMAL'\n",
    "pneumonia_test = r'C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\chest_xray\\test\\PNEUMONIA'\n",
    "\n",
    "annotations_test_normal,_ = annotation_creation(normal_test)\n",
    "_,annotations_test_pneumonia = annotation_creation(pneumonia_test)\n",
    "\n",
    "print(f'Nº normal images for test {len(annotations_test_normal)}')\n",
    "print(f'Nº pneumonia images for test {len(annotations_test_pneumonia)}')\n",
    "print(f'Total images for test {len(annotations_test_normal) + len(annotations_test_pneumonia)}')\n",
    "print(f' Proportion of normal images for test {len(annotations_test_normal)*100/ (len(annotations_test_normal) + len(annotations_test_pneumonia))}%')\n",
    "\n",
    "annotaded_test_images = annotations_test_normal + annotations_test_pneumonia\n",
    "\n",
    "print( annotaded_test_images)\n",
    "print(len(annotaded_test_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [int(entry['label']) for entry in annotaded_train_images]\n",
    "labels_val = [int(entry['label']) for entry in annotaded_val_images]\n",
    "labels_test = [int(entry['label']) for entry in annotaded_test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def get_images(annotaded_images,image_list,normal_path,pneumonia_path):\n",
    "#     resize_transform = Resize((224,224))\n",
    "#     for entry in annotaded_images:\n",
    "#         if entry['label'] == 0:\n",
    "#             imaage_path = os.path.join(normal_path, entry['filename'])\n",
    "#             image = read_image(imaage_path)\n",
    "#             image = image.float()\n",
    "#             if image.shape[0] == 3:  # RGB image\n",
    "#                 image = image.mean(dim=0, keepdim=True)  # Convert to grayscale by averaging channels\n",
    "#             image = resize_transform(image)\n",
    "#             image_list.append(image)\n",
    "#         elif entry['label'] == 1:\n",
    "#             imaage_path = os.path.join(pneumonia_path, entry['filename'])\n",
    "#             image = read_image(imaage_path)\n",
    "#             image = image.float()\n",
    "#             if image.shape[0] == 3:  # RGB image\n",
    "#                 image = image.mean(dim=0, keepdim=True)  # Convert to grayscale by averaging channels\n",
    "#             image = resize_transform(image)\n",
    "#             image_list.append(image)\n",
    "        \n",
    "#     image_tensor = torch.stack(image_list)\n",
    "#     return image_tensor\n",
    "   \n",
    "   \n",
    "   \n",
    "\"\"\" Com esta função estava a ter problemaas para carregar as imagens \n",
    "para treino e aplicar dinamicamente transformações para melhorar a variedade de imagens para reduzir overfitting\n",
    "\n",
    "Uma solução mellhor seria fazer load dos paths de cada imagem de acordo com o label e usar uma classe herdada do pytorch Dataset\n",
    "para fazer loading dinamico.\n",
    "\n",
    "É o stardard normal no workflow com pytorch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(annotaded_images, normal_path,pneumonia_path):\n",
    "    \n",
    "    images_paths = []\n",
    "    for annotaded_images in annotaded_images:\n",
    "        if annotaded_images['label'] == 0:\n",
    "            path_normal = os.path.join(normal_path,annotaded_images['filename'])\n",
    "            images_paths.append(path_normal)\n",
    "        elif annotaded_images['label'] == 1:\n",
    "            path_pneumonia = os.path.join(pneumonia_path,annotaded_images['filename'])\n",
    "            images_paths.append(path_pneumonia)\n",
    "            \n",
    "    return images_paths\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,labels,images_path,transform = None):\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        self.labels = labels \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # print(f\"Loading image {index}: {self.images_path[index]}\")  # Debug\n",
    "        image = Image.open(self.images_path[index]).convert('L') # Using PIL to convert the images to grayscale\n",
    "        label = self.labels[index]\n",
    "        # print(f\"Image loaded, applying transform\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # print(f\"Transform applied, returning image and label\")  # Debug    \n",
    "        return image,label\n",
    "           \n",
    "       \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = get_image_path(annotaded_train_images,normal_train,pneumonia_train)\n",
    "val_path = get_image_path(annotaded_val_images, normal_val, pneumonia_val)\n",
    "test_path = get_image_path(annotaded_test_images, normal_test,pneumonia_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PneumoniaDataset(labels_train, train_path, transform=train_transform)\n",
    "for i in range(5):\n",
    "    image, label = dataset[i]\n",
    "    print(f\"Fetched image {i}, label: {label}, image shape: {image.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the DataLoader with num_workers=0\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Test fetching a single batch\n",
    "for batch in train_loader:\n",
    "    images, label = batch\n",
    "    print(f\"Batch loaded: images shape {images.size()}, labels shape {label.size()}\")\n",
    "    break  # Stop after the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Time how long it takes to fetch the first batch\n",
    "start_time = time.time()\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    print(f\"Batch loaded: images shape {images.shape}, labels shape {labels.shape}\")\n",
    "    break\n",
    "end_time = time.time()\n",
    "print(f\"Time to load first batch: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Production\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-rsna\", op_threshs= None)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = torch.nn.Sequential(\n",
    "                                        torch.nn.Dropout(p=0.33), # To improve overfitting issues i was having before\n",
    "                                        torch.nn.Linear(num_features,2)) # Cause in our case doing binary classification\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model.op_threshs = None\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "for param in model.features.parameters(): # This freezes earlier layers, so they don´t update. these alrready learned high level features of x-ray images\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 1e-3, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debugging training<>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)  # Ensure the model is on the correct device\n",
    "model.eval()  # Use eval mode to disable dropout, etc., for debugging\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    print(f\"Batch moved to device: {device}\")\n",
    "    outputs = model(images)  # Forward pass\n",
    "    print(f\"Forward pass completed: outputs shape {outputs.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your PyTorch installation and GPU drivers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    dataset_train = PneumoniaDataset(labels_train,train_path,train_transform) # tirar o transform para notar o erro\n",
    "    dataset_val = PneumoniaDataset(labels_val, val_path)\n",
    "    dataset_test = PneumoniaDataset(labels_test, test_path)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size = 16, shuffle = True, num_workers=4, pin_memory=True)     \n",
    "    val_loader = DataLoader(dataset_val, batch_size = 16, shuffle= False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(dataset_test, batch_size = 16, shuffle= False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num_epochs = 5\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    scaler = GradScaler()\n",
    "    margin = 1e-5\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for  images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                print(f\"Forward pass completed: outputs shape {outputs.size}\")\n",
    "                \n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                print(f\"Loss computed: {loss.item()}\")\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            print(\"Batch processed\")\n",
    "            scaler.update()\n",
    "            break\n",
    "            \n",
    "            _,predictions_train = torch.max(outputs,1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predictions_train == labels).sum().item()\n",
    "                \n",
    "            \n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)  # Multiplying loss.item() (whcich is the average loss per image in the batch) by images.size(0) (wich is the number of images in the batch means we get the total loss of that batch)\n",
    "        epoch_loss = running_loss / len(dataset_train)\n",
    "        epoch_acc = correct_train *100 / total_train\n",
    "        train_acc.append(epoch_acc)\n",
    "        print(f'Epoch {epoch+1} / {num_epochs}, \\n Loss: {epoch_loss}, \\n Accuracy: {epoch_acc}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0  \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predictions_val = torch.max(outputs,1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predictions_val == labels).sum().item()\n",
    "                \n",
    "        epoch_acc_val = correct_val *100 / total_val\n",
    "        val_acc.append(epoch_acc_val)\n",
    "        print(f'Validation accuracy: {epoch_acc_val}')\n",
    "        \n",
    "        \n",
    "        # Early stopping as last measure to avoid overfitting\n",
    "        if epoch_acc_val > best_val_acc + margin:  \n",
    "            best_val_acc = epoch_acc_val\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "            if no_improvement_epochs >= patience:\n",
    "                print('Finished training due to early stopping')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viewing the validation and training acccuracies\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(1,num_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Single figure, adjustable size\n",
    "plt.plot(x, train_acc, label='Training Accuracy', color='red')\n",
    "plt.plot(x, val_acc, label='Validation Accuracy', color='green')\n",
    "plt.title('Training and Validation Accuracies')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend()  # Show the labels\n",
    "plt.grid(False)  # Optional: adds a grid for readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r'C:\\Users\\helto\\OneDrive\\Documentos\\Mestrado Ciência de Dados\\2º Semestre\\Cloud Computing\\Projeto\\Training Service\\models_saved\\model01.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
